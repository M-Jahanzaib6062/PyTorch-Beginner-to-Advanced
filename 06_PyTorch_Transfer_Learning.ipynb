{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWp2rCqVD96rRNOJdgLUWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Jahanzaib6062/PyTorch-Beginner-to-Advanced/blob/main/06_PyTorch_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**06. PyTorch Transfer Learning**"
      ],
      "metadata": {
        "id": "4kqGYQ_QDAWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6bG2O6cBXoI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  from torchinfo import summary"
      ],
      "metadata": {
        "id": "3EtZuD0mDfJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "i0HOExM4D3X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Get Data"
      ],
      "metadata": {
        "id": "m_ViAdDpEOFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('project/data/')\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f'Path exists!')\n",
        "else:\n",
        "  image_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "  with open(data_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
        "    request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "    f.write(request.content)\n",
        "\n",
        "  with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip') as zip_ref:\n",
        "    zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "LHvWeZCyEJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'"
      ],
      "metadata": {
        "id": "oBqu2pktFja4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "06Hy43S_Fz8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile project/helper_scripts/data_setup.py\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def GetDataLoaders(\n",
        "                  train_path : str,\n",
        "                  test_path : str,\n",
        "                  transform : transforms.Compose,\n",
        "                  batch_size : int,\n",
        "                  workers : int\n",
        "              ):\n",
        "  train_dataset = datasets.ImageFolder(root = train_path,\n",
        "                                      transform = transform)\n",
        "  test_dataset = datasets.ImageFolder(root = test_path,\n",
        "                                      transform = transform)\n",
        "  class_names = train_dataset.classes\n",
        "\n",
        "  train_dataloader = DataLoader(dataset = train_dataset,\n",
        "                                batch_size = batch_size,\n",
        "                                shuffle = True,\n",
        "                                num_workers = workers,\n",
        "                                pin_memory = True)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset,\n",
        "                               batch_size = batch_size,\n",
        "                               shuffle = False,\n",
        "                               num_workers = workers,\n",
        "                               pin_memory = True)\n",
        "  return train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "yVMmK2wvFzFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from project.helper_scripts.data_setup import GetDataLoaders"
      ],
      "metadata": {
        "id": "bnTsA6deF97Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_transform = transforms.Compose([\n",
        "    transforms.Resize(size = (224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "ANYC86U9G0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "batch_size = 32\n",
        "workers = os.cpu_count()\n",
        "train_dataloader, test_dataloader, class_names = GetDataLoaders(train_dir,\n",
        "                                                                test_dir,\n",
        "                                                                manual_transform,\n",
        "                                                                batch_size, workers)\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "bt3Fqbj0HZc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "weights"
      ],
      "metadata": {
        "id": "MUbbs2PiH9Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_transform = weights.transforms()\n",
        "auto_transform"
      ],
      "metadata": {
        "id": "F_tkaWT_IHcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names = GetDataLoaders(train_dir,\n",
        "                                                                test_dir,\n",
        "                                                                auto_transform,\n",
        "                                                                batch_size,\n",
        "                                                                workers)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "jd2OYMyaITI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Getting a pretrained model"
      ],
      "metadata": {
        "id": "8YD-iNSfIji4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "model\n"
      ],
      "metadata": {
        "id": "N4RbV1yXImjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size = (32, 3, 224, 224),col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "hmfkQwrrI6Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "jYUZw6SzJA1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p = 0.2, inplace = True),\n",
        "    nn.Linear(in_features = 1280, out_features = len(class_names), bias = True)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "5NAyfXhEJdQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        "        )"
      ],
      "metadata": {
        "id": "EItcudi5JxFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Train Model\n"
      ],
      "metadata": {
        "id": "N0BZ-R6RKB_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile project/helper_scripts/engine.py\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def TrainStep(\n",
        "                model : torch.nn.Module,\n",
        "                dataloader : torch.utils.data.DataLoader,\n",
        "                loss_func : torch.nn.Module,\n",
        "                optimizer : torch.optim.Optimizer,\n",
        "                device\n",
        "            ):\n",
        "  model.train()\n",
        "  train_accuracy, train_loss = 0, 0\n",
        "  for X, y in dataloader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    logits = model(X)\n",
        "    loss = loss_func(logits, y)\n",
        "    train_loss += loss.item()\n",
        "    y_pred = torch.argmax(torch.softmax(logits, dim = 1), dim = 1)\n",
        "    train_accuracy += (y == y_pred).sum().item() / len(y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss /= len(dataloader)\n",
        "  train_accuracy /= len(dataloader)\n",
        "  return train_loss, train_accuracy\n",
        "\n",
        "def TestStep(\n",
        "              model : torch.nn.Module,\n",
        "              dataloader : torch.utils.data.DataLoader,\n",
        "              loss_func : torch.nn.Module,\n",
        "              device\n",
        "          ):\n",
        "  model.eval()\n",
        "  test_loss, test_accuracy = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for X, y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      logits = model(X)\n",
        "      loss = loss_func(logits, y)\n",
        "      test_loss += loss.item()\n",
        "      y_pred = torch.argmax(torch.softmax(logits, dim = 1), dim = 1)\n",
        "      test_accuracy += (y == y_pred).sum().item() / len(y)\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_accuracy /= len(dataloader)\n",
        "  return test_loss, test_accuracy\n",
        "\n",
        "def Train(\n",
        "            model : torch.nn.Module,\n",
        "            train_dataloader : torch.utils.data.DataLoader,\n",
        "            test_dataloader : torch.utils.data.DataLoader,\n",
        "            loss_func : torch.nn.Module,\n",
        "            optimizer : torch.optim.Optimizer,\n",
        "            epochs : int,\n",
        "            device\n",
        "        ):\n",
        "  results = {\n",
        "      'train_loss' : [],\n",
        "      'train_accuracy' : [],\n",
        "      'test_loss' : [],\n",
        "      'test_accuracy' : []\n",
        "  }\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_accuracy = TrainStep(model, train_dataloader,\n",
        "                                            loss_func, optimizer, device)\n",
        "    test_loss, test_accuracy = TestStep(model, test_dataloader,\n",
        "                                        loss_func, device)\n",
        "    print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_accuracy:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_accuracy:.4f}\"\n",
        "      )\n",
        "\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_accuracy'].append(train_accuracy)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['test_accuracy'].append(test_accuracy)\n",
        "\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "JqSKBCSlKEEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from project.helper_scripts.engine import Train"
      ],
      "metadata": {
        "id": "rzpnknMB51KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)\n",
        "\n",
        "results = Train(model, train_dataloader, test_dataloader, loss_func, optimizer, epochs, device)\n"
      ],
      "metadata": {
        "id": "u2IVhHAU59_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from project.helper_scripts.helper_functions import plot_loss_curves\n",
        "except:\n",
        "  import requests\n",
        "  with open('project/helper_scripts/helper_functions.py', 'wb') as f:\n",
        "    request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py')\n",
        "    f.write(request.content)\n",
        "  from project.helper_scripts.helper_functions import plot_loss_curves\n"
      ],
      "metadata": {
        "id": "oGz3NLMn6xUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_new = {}\n",
        "results_new['train_loss'] = results['train_loss']\n",
        "results_new['train_acc'] = results['train_accuracy']\n",
        "results_new['test_loss'] = results['test_loss']\n",
        "results_new['test_acc'] = results['test_accuracy']\n",
        "plot_loss_curves(results_new)"
      ],
      "metadata": {
        "id": "AwEhlKEn7ho9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Making Prediction on Image from Test-Set"
      ],
      "metadata": {
        "id": "zZtHgsku81PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def PredPlotImages(model : torch.nn.Module,\n",
        "                   img_path : str,\n",
        "                   img_size : Tuple[int, int],\n",
        "                   class_names : List,\n",
        "                   transform : torchvision.transforms = None,\n",
        "                   device: torch.device = 'cpu'):\n",
        "\n",
        "  image = Image.open(img_path)\n",
        "  if transform is not None:\n",
        "    transformed_image = transform(image)\n",
        "  else:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(size = img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                             std = [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    transformed_image = transform(image)\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    logits = model(torch.unsqueeze(transformed_image, dim = 0).to(device))\n",
        "  probs = torch.softmax(logits, dim = 1)\n",
        "  y_pred = torch.argmax(probs, dim = 1)\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(f'Pred : {class_names[y_pred]} | Prob : {probs.max():.3f}')\n",
        "  plt.axis(False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S8qiw4vj85zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "n_samples = 3\n",
        "\n",
        "image_path_list = list(Path(test_dir).glob('*/*.jpg'))\n",
        "random_image_paths = random.sample(image_path_list, k = n_samples)\n",
        "for image_path in random_image_paths:\n",
        "  PredPlotImages(model, image_path, (224,224), class_names,\n",
        "                 device = device)"
      ],
      "metadata": {
        "id": "U1YRWbm9_B4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ea8yojIgAI62"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}