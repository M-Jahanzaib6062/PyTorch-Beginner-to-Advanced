{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1dmhn+FupZDkc5XxDGy7A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Jahanzaib6062/PyTorch-Beginner-to-Advanced/blob/main/00_PyTorch_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **00. PyTorch Fundamentals**\n",
        "Q. What is PyTorch?\n",
        "\n",
        "A. PyTorch is an open-source Machine Learning and Deep Learning framework.\n",
        "\n",
        "Link to website:https://docs.pytorch.org/docs/stable/index.html\n",
        "\n",
        "Q. What can PyTorch be used for?\n",
        "\n",
        "A. It allows you to manipulate and process data and write machine learning algorithms using python code.\n",
        "\n",
        "Q. Who uses PyTorch?\n",
        "\n",
        "A. Tech giants like Meta, Tesla, Microsoft and many more use PyTorch for there AI development.\n",
        "\n",
        "It is also the most used framework in AI papers.\n"
      ],
      "metadata": {
        "id": "78PPQcIp3pQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing PyTorch***"
      ],
      "metadata": {
        "id": "t4fj_WdS5t3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRyrJiPI3daF",
        "outputId": "6dd957cb-5d97-4ee7-ccd6-df492f3e601b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***PyTorch Tensors***"
      ],
      "metadata": {
        "id": "VckPWhlC69KZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tensors"
      ],
      "metadata": {
        "id": "3Sis2l4zlbx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a whole documentation page dedicated to the [torch.Tensor](https://docs.pytorch.org/docs/stable/tensors.html#torch-tensor) class\n",
        "\n",
        "Let's code.\n",
        "\n",
        "The first thing we are going to create is a **scalar**.\n",
        "\n",
        "A scalar is a single number and in tensor-speak it is a zero dimensional tensor."
      ],
      "metadata": {
        "id": "PvV3SSeu7E3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(3)\n",
        "print(scalar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FDZpos57Dyh",
        "outputId": "f11e2f82-7d39-4ddf-f7c6-f6f144818c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensor(3)** represents a scalar value of type **torch.Tensor**.\n",
        "\n",
        "Let's check the dimensions of this tensor."
      ],
      "metadata": {
        "id": "VIHcWRRo84Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(scalar.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Eu2QNG9IOM",
        "outputId": "9432ea2e-75dd-4e89-d186-1cd4f8d64920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve value from this tensor, we can use the \"item()\" method."
      ],
      "metadata": {
        "id": "R_9gmY8Q9UzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_value = scalar.item()\n",
        "print(tensor_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzjrSw2_9fFd",
        "outputId": "b82c60db-ad0a-402e-8c4c-4401203792f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectors"
      ],
      "metadata": {
        "id": "qChsq2teliSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, now let's see a vector.\n",
        "\n",
        "A vector is a single dimension tensor but can contain many numbers.\n",
        "\n",
        "As in, you could have a vector [3, 2] to describe [bedrooms, bathrooms] in your house. Or you could have [3, 2, 2] to describe [bedrooms, bathrooms, car_parks] in your house.\n",
        "\n",
        "The important trend here is that a vector is flexible in what it can represent (the same with tensors)."
      ],
      "metadata": {
        "id": "TDXtrd_lMDw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([3, 7])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn0CcbWjMHQt",
        "outputId": "ae0cf9ce-2f31-4658-8de4-0f035a26a16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the important question is that how many dimensions a vector has?\n",
        "\n",
        "To find that we can use the \"ndim\" property."
      ],
      "metadata": {
        "id": "95eM4NYEMitS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6MxqGunMycq",
        "outputId": "b5324968-4af3-4a59-e65a-f4aaa3f444e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, a vector has 1 dimension.\n",
        "\n",
        "\n",
        "\n",
        "An easy way to understand this is to think about how many dimensions do you need to access data in the tensor.\n",
        "\n",
        "And since you only need 1 dimension for a vector, so it has one dimension."
      ],
      "metadata": {
        "id": "CJ0Plzi9M0-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trick 1:**\n",
        "\n",
        "One useful trick to find the dimensions of any tensor is to count the number of closing brackets at the end of the tensor.\n",
        "\n",
        "e.g.\n",
        "\n",
        "my_tensor = torch.tensor(\n",
        "\n",
        "  [[1, 2, 3],\n",
        "  \n",
        "   [4, 5, 6]] )\n",
        "\n",
        "Since there are two closing brackets at the end so 'my_tensor' is 2-D.\n",
        "\n",
        "=> Such a tensor is called a \"Matrix\"."
      ],
      "metadata": {
        "id": "7Gvn_aTHNl4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next important thing to discuss about a tensor is its 'Shape'.\n",
        "\n",
        "\"shape\" property is used to get the shape of a tensor."
      ],
      "metadata": {
        "id": "fz-EdZXOOonR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2Is0fWtNKrZ",
        "outputId": "5e7f96d0-36d9-4bbd-d34f-426a408705e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above returns torch.Size([2]) which means our vector has a shape of [2]. This is because of the two elements we placed inside the square brackets ([3, 7]).\n",
        "\n"
      ],
      "metadata": {
        "id": "11y5qN_gPDwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trick 2:**\n",
        "\n",
        "The shape of a tensor can be determined by counting how many elements are there in each dimension."
      ],
      "metadata": {
        "id": "7kh0rUZsRSEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix"
      ],
      "metadata": {
        "id": "I6IC9pf5lud0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see a Matrix\n"
      ],
      "metadata": {
        "id": "UxpujU_qPLcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Matrix = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "print(Matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4UADGrHO-sB",
        "outputId": "a9af93dc-4abe-40be-a2d2-587df7228e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of \"Matrix\" is {Matrix.shape}')\n",
        "print(f'\"Matrix\" is {Matrix.ndim} dimensional')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwa5_dofP2hQ",
        "outputId": "d6bae7f6-4468-48fd-ffb1-e7a4ee765ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of \"Matrix\" is torch.Size([2, 3])\n",
            "\"Matrix\" is 2 dimensional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same way we can create tensors of 'shape' and any 'dimension'.\n",
        "\n",
        "e.g.\n"
      ],
      "metadata": {
        "id": "VQNBnm2EQTic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor(\n",
        "    [[[1, 2, 3],\n",
        "      [4, 5, 6],\n",
        "      [7, 8, 9]]]\n",
        ")\n",
        "print(tensor)\n",
        "print(f'Shape of \"tensor\" is {tensor.shape}')\n",
        "print(f'\"tensor\" is {tensor.ndim} dimensional')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQBQQQNdQFCP",
        "outputId": "763f0a02-dfc9-440a-8747-716cb8c05a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "Shape of \"tensor\" is torch.Size([1, 3, 3])\n",
            "\"tensor\" is 3 dimensional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors"
      ],
      "metadata": {
        "id": "KBr16hXaRvdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a random tensor using 'torch.rand()' function with 'size' parameter."
      ],
      "metadata": {
        "id": "WnoQTe6USFy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(size = (3, 4))\n",
        "print(random_tensor)\n",
        "print(f'The DataType of tensor is {random_tensor.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tBcn5hLRBbY",
        "outputId": "d32a968b-7bda-49c6-bd36-b6ce20caa945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4518, 0.5870, 0.5703, 0.6243],\n",
            "        [0.4053, 0.9303, 0.9399, 0.9811],\n",
            "        [0.0250, 0.1591, 0.8895, 0.5989]])\n",
            "The DataType of tensor is torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros and Ones"
      ],
      "metadata": {
        "id": "RFTXgClfSoSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_tensor = torch.zeros(size = (2, 2))\n",
        "print(zeros_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOshdb8PSqpu",
        "outputId": "800d2bea-e5a5-47e3-d373-da7eecae2113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_tensor = torch.ones(size = (3, 3))\n",
        "print(ones_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppcSQejWTAYF",
        "outputId": "1912f88a-0281-47fa-f659-c3c742056b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a range and tensors like"
      ],
      "metadata": {
        "id": "8AXfNF05TKPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
        "\n",
        "You can use torch.arange(start, end, step) to do so.\n",
        "\n",
        "Where:\n",
        "\n",
        "* start = start of range (e.g. 0)\n",
        "* end = end of range (e.g. 10)\n",
        "* step = how many steps in between each value (e.g. 1)"
      ],
      "metadata": {
        "id": "ReVdB_y8TQ2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(start = 1, end = 11, step = 1)\n",
        "print(one_to_ten)\n",
        "# Notice that the end is not included.\n",
        "# So to go from 1 to 100, where 100 should be included you would use end = 101."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXZTCwYyTocK",
        "outputId": "63a6a069-8074-4397-aebc-a792ca77379b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use torch.zeros_like(input) or torch.ones_like(input) which return a tensor filled with zeros or ones in the same shape as the input respectively."
      ],
      "metadata": {
        "id": "V0aLbbQGULBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorA = torch.tensor([[1, 2, 3],\n",
        "                        [4, 5, 6]], dtype = torch.float16)\n",
        "print(tensorA)\n",
        "print(f'Shape is {tensorA.shape}')\n",
        "print(f'dytpe is {tensorA.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPMf9DuVUPwW",
        "outputId": "91fffc44-11e7-4f56-f17d-c71bb4617440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float16)\n",
            "Shape is torch.Size([2, 3])\n",
            "dytpe is torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_like_tensorA = torch.zeros_like(tensorA)\n",
        "print(zeros_like_tensorA)\n",
        "print(f'Shape is {zeros_like_tensorA.shape}')\n",
        "print(f'dtype is {zeros_like_tensorA.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sviePyl7UBiT",
        "outputId": "a26d58c5-86c5-4460-80d3-ab958c315991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "Shape is torch.Size([2, 3])\n",
            "dtype is torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_like_tensorA = torch.ones_like(tensorA)\n",
        "print(ones_like_tensorA)\n",
        "print(f'Shape is {ones_like_tensorA.shape}')\n",
        "print(f'dtype is {ones_like_tensorA.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUxVXmADUzdU",
        "outputId": "99b31b8b-00b4-4e19-dbc3-39959cf099f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float16)\n",
            "Shape is torch.Size([2, 3])\n",
            "dtype is torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensor Datatypes**"
      ],
      "metadata": {
        "id": "H12j55oEVm9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different tensor datatypes available in PyTorch.\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Getting to know which one can take some time.\n",
        "\n",
        "Generally if you see torch.cuda anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is torch.float32 or torch.float.\n",
        "\n",
        "This is referred to as \"32-bit floating point\".\n",
        "\n",
        "But there's also 16-bit floating point (torch.float16 or torch.half) and 64-bit floating point (torch.float64 or torch.double).\n",
        "\n",
        "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "Plus more!\n",
        "\n",
        "Note: An integer is a flat round number like 7 whereas a float has a decimal 7.0.\n",
        "\n",
        "The reason for all of these is to do with precision in computing.\n",
        "\n",
        "Precision is the amount of detail used to describe a number.\n",
        "\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
        "\n",
        "Resources:\n",
        "\n",
        "See the PyTorch documentation for a list of all available tensor datatypes.\n",
        "\n",
        "Link: https://docs.pytorch.org/docs/stable/tensors.html#torch-tensor\n",
        "\n",
        "Read the Wikipedia page for an overview of what precision in computing) is.\n",
        "\n",
        "Link: https://en.wikipedia.org/wiki/Precision_(computer_science)"
      ],
      "metadata": {
        "id": "mdFHALGHVsFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float32_tensor = torch.tensor([1, 2, 3], dtype = torch.float32)\n",
        "print(float32_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92EBAEQ9Vp_x",
        "outputId": "aba2c167-56cd-4cad-b690-623cab9dd76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float16_tensor = torch.tensor([1, 2, 3], dtype = torch.float16)\n",
        "print(float16_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVKienllWaLj",
        "outputId": "ad659bc8-6500-4e4a-f31a-202f5c886631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Information about tensors**\n"
      ],
      "metadata": {
        "id": "UIkvC1RzWuYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the most important properties of a tensor are:\n",
        "* datatype\n",
        "* shape\n",
        "* device\n",
        "\n",
        "e.g."
      ],
      "metadata": {
        "id": "3-ooh61_W8-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor(\n",
        "    [[1, 2, 3],\n",
        "     [4, 5, 6]], dtype = torch.float32\n",
        ")\n",
        "print(tensor)\n",
        "print(f'It\\'s shape is {tensor.shape}')\n",
        "print(f'It\\'s dtype is {tensor.dtype}')\n",
        "print(f'It\\'s stored on {tensor.device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR4SGPcQXMzR",
        "outputId": "1bbaccaa-a70c-485e-e425-73e4ae3bb27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "It's shape is torch.Size([2, 3])\n",
            "It's dtype is torch.float32\n",
            "It's stored on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When you run into issues in PyTorch, it's very often one to do with one of the three attributes above."
      ],
      "metadata": {
        "id": "9IXsLOJoX5RZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Manipulating Tensors (Tensor Operations)**"
      ],
      "metadata": {
        "id": "fnOW1OPNX9Cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, data (images, text, video, audio, DNA structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be millions and billions) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ],
      "metadata": {
        "id": "v1IMMkMoXzR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Operations"
      ],
      "metadata": {
        "id": "TQC1carUY05x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3, 4])\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHsdEydPYyAp",
        "outputId": "774b5519-7251-49a5-92cf-c4ede98fdb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor + 10) # Element-wise Addition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt_W4_gpZZC7",
        "outputId": "26d6e31f-2acc-458e-d57d-480acdf0905c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor - 100) # Element-wise Subtraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AK1E5L6Zd7A",
        "outputId": "8edbaecf-6576-4e50-cf59-bd2a315755b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-99, -98, -97, -96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor * 10) # Element-wise Multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2i6q8K4ZigQ",
        "outputId": "6695aa15-06e9-4572-c906-0a5e457ceef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use PyTorch's built-in functions."
      ],
      "metadata": {
        "id": "0vk_DU0fZyvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.add(tensor, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hlrk2q9ZpIq",
        "outputId": "48767bed-26ec-460d-f5c4-d23101ecf6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.subtract(tensor, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP_ymrDDZ8WW",
        "outputId": "47df1e24-e238-4ddc-bfd3-947672b0d506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-99, -98, -97, -96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.mul(tensor, 10)) # torch.mul short for torch.multiply"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkBMOlx0aAGI",
        "outputId": "5628bc36-7288-40dd-cf14-28a5493a7102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication"
      ],
      "metadata": {
        "id": "LhGAEtAIaR-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the 'torch.matmul()' method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "The inner dimensions must match:\n",
        "* (3, 2) @ (3, 2) won't work\n",
        "* (2, 3) @ (3, 2) will work\n",
        "* (3, 2) @ (2, 3) will work\n",
        "\n",
        "The resulting matrix has the shape of the outer dimensions:\n",
        "* (2, 3) @ (3, 2) -> (2, 2)\n",
        "* (3, 2) @ (2, 3) -> (3, 3)\n",
        "\n",
        "*Note:* The '@' symbol represents matrix multication in python.\n",
        "\n",
        " Link to 'torch.matmul()' : https://docs.pytorch.org/docs/stable/generated/torch.matmul.html#torch-matmul"
      ],
      "metadata": {
        "id": "o_CvVb7VaC-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPq8p7Zwa8Dq",
        "outputId": "94dd93fb-026b-4c6b-b1ce-904728def907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxAUDAtnbMHe",
        "outputId": "6c30e3c5-ca3a-40ba-b317-37bf760d3344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since, [1 * 1, 2 * 2, 3 * 3] = [1, 4, 9]"
      ],
      "metadata": {
        "id": "xkZI-8KibSh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iaTSr15bOFQ",
        "outputId": "a2ed0a7a-d2f3-4b83-b793-46f8ed0a3b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since, [1 * 1 + 2 * 2 + 3 * 3] = 14"
      ],
      "metadata": {
        "id": "g9S-k1aWbbvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication using loop\n",
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szuXR3l2bqpQ",
        "outputId": "63f10639-48b5-4ce2-c2a7-164fc8547931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14)\n",
            "CPU times: user 1.52 ms, sys: 0 ns, total: 1.52 ms\n",
            "Wall time: 1.38 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication using torch.matmul()\n",
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeMFQZzZbqlG",
        "outputId": "31833499-a0f1-4f29-ec4d-188262614df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 585 µs, sys: 18 µs, total: 603 µs\n",
            "Wall time: 470 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference is so subtle because the loop version performs computation sequentially while the torch.matmul() do parallel computing.\n"
      ],
      "metadata": {
        "id": "D6yHVJbacQgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using transpose()\n",
        "tensor1 = torch.rand(2, 3)\n",
        "print(tensor1, tensor1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LJ6VZB3bnwP",
        "outputId": "4c9b1e47-4344-45f5-c325-439b6a209ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4461, 0.9350, 0.1114],\n",
            "        [0.9643, 0.7778, 0.8134]]) torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we multiply them it will give error because of shape\n",
        "torch.matmul(tensor1, tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "ySouwEZZc0mT",
        "outputId": "d0dc820f-63b1-4d67-a778-035ee6ae2699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-45-3388781343.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if we multiply them it will give error because of shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we can use take transpose of the first or second tensor in this case.\n",
        "torch.matmul(tensor1,tensor1.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec9GrLkFc_kf",
        "outputId": "6409dc51-d239-4b24-e4f1-32a81dbabb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0855, 1.2480],\n",
              "        [1.2480, 2.1966]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can understand matrix multiplication visually at\n",
        "http://matrixmultiplication.xyz/."
      ],
      "metadata": {
        "id": "j52irLF1daNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aggregation**"
      ],
      "metadata": {
        "id": "nSgSjp7SeXWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the min, max, mean, sum, etc."
      ],
      "metadata": {
        "id": "V-SpxIlzeelm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(0, 100, 10)\n",
        "print(tensor, tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK4XNze2di9M",
        "outputId": "d84fb61f-71f0-4739-a903-3395e2742282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "98BhOQbte45Z",
        "outputId": "a5a066c8-5376-47cc-d046-e433a7f7a4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-55-767617123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error says it '.mean()' requires the input tensor to be of dtype = 'float'"
      ],
      "metadata": {
        "id": "EouKNdrXe8Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution: First convert the tensor dtype to float32 and then call mean()\n",
        "print(tensor.type(torch.float32).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6N1S1alfKR7",
        "outputId": "d48d6740-db1b-47d9-b1fd-a65e259c8cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuDxKpP5fWK9",
        "outputId": "46736c36-bd5d-4092-e7d0-8822160e19f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0OYUL48fZX4",
        "outputId": "e9229fbc-66ee-444b-b21a-f4fe88602a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9CcxtLGfbex",
        "outputId": "9920460a-de25-4d98-ae80-da2833e48919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(450)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use the built-in functions."
      ],
      "metadata": {
        "id": "u-H6EKSRfh1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(tensor.type(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d9R90Cfm9x",
        "outputId": "e086015d-e661-4a95-b404-01fc78ed96f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45.)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7fjOekjftKU",
        "outputId": "0cbd8e77-87f2-4762-811c-16846ccca7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAN-9R5KfovH",
        "outputId": "fc05d89c-a90c-4e56-dcce-797acc51d643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(90)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hg2FVAgfv7h",
        "outputId": "ee7aab29-51b6-4029-b163-fc70d99d4f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(450)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's talk about the 'Positional min/max'"
      ],
      "metadata": {
        "id": "msBWRhPqfzag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also find the index of a tensor where the max or minimum occurs with 'torch.argmax()' and 'torch.argmin()' respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the softmax activation function)."
      ],
      "metadata": {
        "id": "ggrNT0Fjf-yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([10, 20, 40])\n",
        "print(tensor, tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOZPZnnFfxMA",
        "outputId": "a2df60f2-e9b2-45e8-8694-1d5f415fa879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 40]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The minimum number is on index {tensor.argmin()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7TpIgggQZ3",
        "outputId": "60e85647-5ff9-44aa-f7ea-4482190f9551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The minimum number is on index 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The maximum number is on index {tensor.argmax()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzEZFQgNgYNx",
        "outputId": "f7308cce-efee-46e2-cdf1-38c9cdb16d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum number is on index 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping, stacking, squeezing and unsqueezing"
      ],
      "metadata": {
        "id": "geesMP7tgpnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:"
      ],
      "metadata": {
        "id": "nxEDyXoAgtpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping"
      ],
      "metadata": {
        "id": "9Uc4ge4igzcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(1, 11)\n",
        "print(tensor, tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnf7fuxegb2B",
        "outputId": "4b1fa3d5-8a33-4579-daea-672fdcac7523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = tensor.reshape(shape = (2, 5))\n",
        "print(reshaped_tensor)\n",
        "print(f'Shape is {reshaped_tensor.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LleLkDGeg-o7",
        "outputId": "0dcfdd0c-6d15-4c45-975d-be40d463cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10]])\n",
            "Shape is torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the new shape such that the number of element must be equal in both tensors"
      ],
      "metadata": {
        "id": "ksjPyVePhVDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View"
      ],
      "metadata": {
        "id": "88We7VQHho3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_view = tensor.view(1, 10)\n",
        "print(tensor_view)\n",
        "print(f'Shape is {tensor_view.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8RvAnEUher0",
        "outputId": "ad646cbb-5824-4d9a-e859-ae157f412b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "Shape is torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stack"
      ],
      "metadata": {
        "id": "_VNBYu1Th9wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vertical_stacked_tensors = torch.stack([tensor, tensor], dim = 0)\n",
        "print(vertical_stacked_tensors)\n",
        "print(vertical_stacked_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn1rcD38iDCc",
        "outputId": "70eb2369-8656-4ae2-e3cd-23ff5226b93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "torch.Size([2, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horizontal_stacked_tensors = torch.stack([tensor, tensor], dim = 1)\n",
        "print(horizontal_stacked_tensors)\n",
        "print(horizontal_stacked_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYr7E4ddiUgu",
        "outputId": "7abd9f12-781b-4995-cd6d-3032d8a95b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  1],\n",
            "        [ 2,  2],\n",
            "        [ 3,  3],\n",
            "        [ 4,  4],\n",
            "        [ 5,  5],\n",
            "        [ 6,  6],\n",
            "        [ 7,  7],\n",
            "        [ 8,  8],\n",
            "        [ 9,  9],\n",
            "        [10, 10]])\n",
            "torch.Size([10, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Squeeze / Unsqueeze"
      ],
      "metadata": {
        "id": "FasDG1IXigPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.squeeze() removes a single dimension from the tensor.\n",
        "\n",
        "e.g."
      ],
      "metadata": {
        "id": "NLgeEj_nimE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(size = (1, 10))\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RYesmwsic00",
        "outputId": "414c39a6-b3d6-4ff2-9676-c267475913b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1293, 0.3254, 0.0968, 0.7273, 0.0883, 0.7129, 0.5872, 0.0516, 0.1394,\n",
            "         0.8539]])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_tensor = torch.squeeze(tensor, dim = 0)\n",
        "print(squeezed_tensor)\n",
        "print(squeezed_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3oz3gbsi0wi",
        "outputId": "bc7d612f-eaa3-467e-a319-76ab945554a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1293, 0.3254, 0.0968, 0.7273, 0.0883, 0.7129, 0.5872, 0.0516, 0.1394,\n",
            "        0.8539])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.unsqueeze() do the opposite, it add a single dimension as specified."
      ],
      "metadata": {
        "id": "0UoeZg2ujKfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unsqueezed_tensor = torch.unsqueeze(squeezed_tensor, dim = 0)\n",
        "print(unsqueezed_tensor)\n",
        "print(unsqueezed_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaGnRrfSjKHS",
        "outputId": "8b968bae-f08a-4961-e56f-39e33285c8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1293, 0.3254, 0.0968, 0.7273, 0.0883, 0.7129, 0.5872, 0.0516, 0.1394,\n",
            "         0.8539]])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsqueezed_tensor = torch.unsqueeze(squeezed_tensor, dim = 1)\n",
        "print(unsqueezed_tensor)\n",
        "print(unsqueezed_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQM-OFqsj2FH",
        "outputId": "edfca6bc-0067-46f7-c638-821029b96741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1293],\n",
            "        [0.3254],\n",
            "        [0.0968],\n",
            "        [0.7273],\n",
            "        [0.0883],\n",
            "        [0.7129],\n",
            "        [0.5872],\n",
            "        [0.0516],\n",
            "        [0.1394],\n",
            "        [0.8539]])\n",
            "torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permute"
      ],
      "metadata": {
        "id": "BNdGf8Kkj1JL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also rearrange the order of axes values with 'torch.permute(input, dims)', where the input gets turned into a view with new dims."
      ],
      "metadata": {
        "id": "bIeQeYqUkS-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_org = torch.rand(size = (224, 224, 3))\n",
        "tensor_perm = tensor_org.permute(2, 0, 1)\n",
        "print(tensor_perm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzjJX5d4kSZg",
        "outputId": "732e1527-c7d3-4241-bac5-559e0dea5747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Indexing**"
      ],
      "metadata": {
        "id": "wXOfclrwkwXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "kSs5bvfPky06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve specific data items from any tensor, indexing can be used.\n",
        "\n",
        "It is quite similar to how indexing works with python lists and numpy arrays.\n",
        "\n",
        "Indexing goes from outer-dimension -> inner-dimension.\n",
        "\n",
        "e.g."
      ],
      "metadata": {
        "id": "VWXuEzIKSy_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(1, 10).reshape(shape = (1, 3, 3))\n",
        "print(tensor, tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpfQ9PiCRxLM",
        "outputId": "1a206f6c-36fe-48e0-9b5b-0b45dcd44011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[0]) # outer bracket\n",
        "print(tensor[0][0]) #inner bracket or 0'th row\n",
        "print(tensor[0][0][0]) #inner element or 0'th column of 0'th row of 0'th outer bracket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejxri8wGTR37",
        "outputId": "b06569f3-7d28-4978-a645-b5c3a9ecc9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([1, 2, 3])\n",
            "tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use \" : \" to specify \"all values in this dimension\" and then use a comma (,) to add another dimension."
      ],
      "metadata": {
        "id": "PojBgQlKTwJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:,0]) # First row of all the bigger elements in the first dimension\n",
        "print(tensor[0, 1, 1]) # to retrieve 5\n",
        "print(tensor[0, :, 2]) # to retrieve last column values from each row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc5CxzUfTuFz",
        "outputId": "32a104f3-69f3-4503-948b-eb8412e44702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "tensor(5)\n",
            "tensor([3, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch tensors and Numpy**"
      ],
      "metadata": {
        "id": "Q37R4qdMUZKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "\n",
        "* torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
        "* torch.Tensor.numpy() - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "PhiAIb4XVG86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Vq_52O7GUO_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1., 11.)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d8B71n5VP0x",
        "outputId": "25e0e90e-ea3a-4675-8583-278b64c6f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
              " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(1, 11).reshape(shape = (2, 5))\n",
        "np_tensor = tensor.numpy()\n",
        "tensor, np_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMs0SCV1WAd-",
        "outputId": "b7a587c1-bd02-41e3-f7d5-bc1e9fc0b2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1,  2,  3,  4,  5],\n",
              "         [ 6,  7,  8,  9, 10]]),\n",
              " array([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reproducibility**"
      ],
      "metadata": {
        "id": "2Q1-jZ_MWSqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where reproducibility comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ],
      "metadata": {
        "id": "VCLXLcLXWW8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(3, 4)\n",
        "tensor2 = torch.rand(3, 4)\n",
        "print(f'Tensor 1: \\n{tensor1}\\n')\n",
        "print(f'Tensor 2: \\n{tensor2}\\n')\n",
        "print(f'Do they have same values:\\n{tensor1 == tensor2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CflgSoEaXAZm",
        "outputId": "fb87a3ad-e6d1-4877-a61c-4c59ce825f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1: \n",
            "tensor([[0.7493, 0.9975, 0.5042, 0.3771],\n",
            "        [0.6768, 0.4907, 0.6441, 0.9924],\n",
            "        [0.9901, 0.4614, 0.8121, 0.2624]])\n",
            "\n",
            "Tensor 2: \n",
            "tensor([[0.2810, 0.6617, 0.9495, 0.1346],\n",
            "        [0.7697, 0.7947, 0.7077, 0.4072],\n",
            "        [0.6257, 0.9457, 0.6070, 0.7115]])\n",
            "\n",
            "Do they have same values:\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as you might've expected, the tensors come out with different values.\n",
        "\n",
        "But what if you wanted to create two random tensors with the same values.\n",
        "\n",
        "That's where \" torch.manual_seed(seed) \"comes in, where seed is an integer (like 42 but it could be anything) that effects the randomness.\n",
        "\n",
        "Let's try it out by creating some more  random tensors."
      ],
      "metadata": {
        "id": "HuNm47mcX1E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "tensor1 = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "tensor2 = torch.rand(3, 4)\n",
        "\n",
        "print(f'Tensor 1: \\n{tensor1}\\n')\n",
        "print(f'Tensor 2: \\n{tensor2}\\n')\n",
        "print(f'Do they have same values:\\n{tensor1 == tensor2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYfGxLV0XzW_",
        "outputId": "b7ec2772-f56a-4900-e462-b944ecc8d60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1: \n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor 2: \n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Do they have same values:\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "print(torch.rand(3))\n",
        "torch.manual_seed(42)\n",
        "print(torch.rand(3, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjd1urwsYot6",
        "outputId": "320db88e-22fa-4fbb-9f9c-0bbc1f07561a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8823, 0.9150, 0.3829])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
            "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
            "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running tensors on GPUs**"
      ],
      "metadata": {
        "id": "q2FozF-IZAl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
        "\n",
        "Your computer might have one.\n",
        "\n",
        "If so, you should look to use it whenever you can to train neural networks because chances are it'll speed up the training time dramatically."
      ],
      "metadata": {
        "id": "HvcLiDaCZMYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU on google colab"
      ],
      "metadata": {
        "id": "NwaMuNsgZxcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Goto the \"Runtime\", Select \"Change runtime type\" then select \"Hardware accelerator\" to \"T4 GPU\"."
      ],
      "metadata": {
        "id": "MxrOljkEZ8UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yydCdJv6Y34h",
        "outputId": "1e5c7ba8-707a-4363-a37c-3ff634f82588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul 27 05:56:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting PyTorch to run on the GPU"
      ],
      "metadata": {
        "id": "ji9npldtapo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to check whether PyTorch has access to a GPU.\n",
        "\n",
        "This can be done using \"torch.cuda.is_available()\"."
      ],
      "metadata": {
        "id": "Z54OMvY0auWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-iKQF0sa9lj",
        "outputId": "f04cea7a-7ddf-4293-b8d7-e864da9e82a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above outputs True, PyTorch can see and use the GPU, if it outputs False, it can't see the GPU and in that case, you'll have to go back through the installation steps.\n",
        "\n",
        "Now, let's say you wanted to setup your code so it ran on CPU or the GPU if it was available.\n",
        "\n",
        "That way, if you or someone decides to run your code, it'll work regardless of the computing device they're using.\n",
        "\n",
        "Let's create a device variable to store what kind of device is available."
      ],
      "metadata": {
        "id": "TmsxeeaCbdh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4DWB_ifobf-5",
        "outputId": "00b7b3b8-8ea9-48fc-976c-98029c1c3bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above output \"cuda\" it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output \"cpu\", our PyTorch code will stick with the CPU.\n",
        "\n",
        "**Note:** In PyTorch, it's best practice to write device agnostic code. This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do much faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using torch.cuda.device_count()."
      ],
      "metadata": {
        "id": "9kCKl5GsboIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CauYWwXFbsv5",
        "outputId": "a3679bb5-4260-44ce-a8cd-081edd7b7497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting models or tensors on GPU"
      ],
      "metadata": {
        "id": "IQgkt5hEb2Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3])\n",
        "print(tensor, tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6EHpQGub6Bs",
        "outputId": "a50b856d-cc21-4c43-a186-59147c4e16d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu = tensor.to(device)\n",
        "print(tensor_on_gpu, tensor_on_gpu.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8gPVhvlcCGc",
        "outputId": "d177c4bb-b25d-4b90-f4ac-2db41cdb63ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving tensor back to CPU"
      ],
      "metadata": {
        "id": "vJgRbQBEcMwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't convert a tensor on GPU to numpy\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "AZKGGPZfcQa5",
        "outputId": "8cc19863-93b2-4f0b-de2d-b6de595558fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3231536582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Can't convert a tensor on GPU to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a tensor back to CPU and usable with NumPy we can use \"Tensor.cpu()\"."
      ],
      "metadata": {
        "id": "YWFO5rZAckVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_cpu = tensor_on_gpu.cpu()\n",
        "print(tensor_on_cpu, tensor_on_cpu.device)\n",
        "print(tensor_on_gpu, tensor_on_gpu.device) # while the original tensor copy stays on the gpu."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqx0GGpLcZ6i",
        "outputId": "367c936e-e18c-44b0-d6d0-b2f2f1fd895d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
          ]
        }
      ]
    }
  ]
}